# Portfolio 

This is the progress of my work and projects I have completed as of now. I do hope to add more projects in my professional portfolio.

------------------------------------------------------------------

### Analysing Singapore Premier League Season 2021/2022 - Tableau 

Being a data analyst in football is my dream job. Gaining insights/patterns/trends from data can help a team win or lose a game. I decided to look at teams in the Singapore Premier League during the season 2021/2022 and see how they performed.

[![View on Tableau](https://img.shields.io/badge/Tableau-View%20on%20Tableau%20Public-brightgreen)]
(https://public.tableau.com/app/profile/vinoth.nanda.kumaran/viz/SingaporePremierLeague-2022SeasonAnalysis_16893830820560/SPLSeason20212022Analysis)

![image](https://i.ytimg.com/vi/26JLRuDyV-g/maxresdefault.jpg)

------------------------------------------------------------------

### Extracting data from an image using OpenCV and PyTesseract 

I have an interest in gaming since young. Add that to football and analytics, I decided to analyse how my team performs. And since there is no data collection in game, I had to extract out data from an image and then convert it to a DataFrame before analysing.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/FIFA-23-Stats-Extraction)

![image](https://www.psu.com/wp/wp-content/uploads/2022/10/FIFA23-2.jpeg)

------------------------------------------------------------------

### SQL Exercises - Wikibooks

I also found SQL exercises on wikibooks to continue practicing my knowledge on SQL.


### The Computer Store

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/SQL-The-Computer-Store)

![image](https://user-images.githubusercontent.com/108440564/186325476-53c2b583-d8b2-44b2-aa87-3ea3b9ba0b0f.png)

------------------------------------------------------------------

### SQL With Danny Ma

I found Danny Ma on Linkedin. https://www.linkedin.com/company/datawithdanny/ 

I followed his page and found case studies for SQL. Continuing to put to practice of my SQL knowledge.

![image](https://user-images.githubusercontent.com/108440564/186323263-e92e194b-8d62-41d6-b9f3-9b0dec12e9d4.png)


------------------------------------------------------------------

### Case Study 1: Danny's Diner

The first is of a diner whereby Danny sells 3 of his favourite foods, sushi, ramen and curry. We analyse the dataset with SQL and proceed to answer questions which will help him in his business.


[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/SQL-Case-Studies/blob/main/README.md#-case-study-1---dannys-diner)
<center><img src="https://user-images.githubusercontent.com/108440564/186323740-33e7777b-80ba-4b5f-9d89-6122d50200ff.png"/></center>

------------------------------------------------------------------

### Case Study 2: Pizza Runner

In order to expand his business, Danny decided to hire pizza runners to help him deliver his pizzas as the demand for pizzas increase! Danny started by recruiting “runners” to deliver fresh pizza from Pizza Runner Headquarters (otherwise known as Danny’s house) and also maxed out his credit card to pay freelance developers to build a mobile app to accept orders from customers.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/SQL-Case-Studies/blob/main/README.md#-case-study-2---pizza-runner)
<center><img src="https://user-images.githubusercontent.com/108440564/186323609-3ac15bc8-f83f-448f-a7da-f5c39cb73f33.png"/></center>

------------------------------------------------------------------

I was told that I needed to learn SQL. Hence, I did a short course on SQL on UDACITY. What better way to practice my SQL than to try and analyse a dataset with SQL on the EUROS 2016?

### European Championship 2016 - SQL Database

I have got around 80 odd questions about the European Championships from 2016 to practice my SQL knowledge.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/European-Football-Database)
<center><img src="https://hongkong.consulfrance.org/IMG/arton10094.jpg?1464315767"/></center>


------------------------------------------------------------------

### Data Science Modelling

In my final module in Data Science, we learnt about ***K-Means clustering, PCA and ML Train-Test Algorithms***. 

For our project, we were advised to apply our knowledge of what we learnt throughout our time in SUTD onto a dataset.

For purposes of achieving a better understanding, we were advised to use previous datasets. We continued with the IBM HR data.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://vinothnk.github.io/Data-Science-Modelling/)


Below is the pipeline we followed for our capstone project for the ***ModularMaster Certificate in Data Science*** course.
<center><img src="https://www.aismartz.com/blog/wp-content/uploads/2019/11/Electronic-Design-Automation-data-science-model.jpg"/></center>

------------------------------------------------------------------

### Data Validation and Statistical Analysis

Statistics are integral for a data analyst/scientist as explained by my lecturer. He mentioned that one may kick off a DS project with a judgemental approach to deciding which approach or technique will suit the project.

The use of statistics is an alternative to make DS a more systematic yet organised approach in terms of being critical and getting objective, data-driven scientific enquiries.

With stats, the data could be validated and required analysis can be conducted.

My group selected the IBM HR data as our dataset.

[![View on Kaggle](https://img.shields.io/badge/Kaggle-View%20on%20Kaggle-orange)](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)

------------------------------------------------------------------

***Parametric Test between Monthly Income and Gender***

We were allowed to use any dataset for this project. We chose Human Resources as one of my group mate was from a HR department and he would have more insight as to how we can use HR data.

We decided to go with Montly Income and Gender as our variables for analysis if there was a disparity between Monthly Income and your gender.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://vinothnk.github.io/Data-Validation-Statistical-Analysis---Parametric/)

------------------------------------------------------------------

***Non-Parametric Test between WorkLifeBalance and MonthlyIncome***

Given that everyone craves and wanted work life balance, we focused on WorkLifeBalance and MonthlyIncome as our variables for the Non-Parametric tests.

The results should let us know if there is any work life balance based on your monthly income.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://vinothnk.github.io/Data-Validation-Statistical-Analysis-Non-Parametric/)

---

### Data Wrangling with Programming

For my next module, we learnt to use Python to perform the following actions :
- data discovery
- data structuring
- data cleaning
- data validation
- data enrichment
- data aggregation

Our group project has 2 parts. 

The first was to clean a dataset which was structured. Meaning that data was either in table format or from a csv/excel file format
which would make it easier to clean.

The second is to clean UNSTRUCTURED data. Examples of such data are Text files, Email, social media, media, mobile data, etc.


***E-Commerce dataset - Structured***

We found the dataset on Kaggle. It was Pakistan's largest e-commerce data. We used this dataset as 1 of the requirement for our project was that
dataset consisted of 100k to 10million rows minimum. This dataset had about 500k rows which fulfilled our project requirements.

[![View on Kaggle](https://img.shields.io/badge/Kaggle-View%20on%20Kaggle-orange)](https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://vinothnk.github.io/Data-Wrangling-with-Programming/)

<center><img src="https://user-images.githubusercontent.com/108440564/179391657-b548ee79-3085-46de-ba72-f0b149871e2a.png"/></center>



***Enron Emails - Un-Structured***

For our un-structured dataset, we decided to go with emails. The reason why we decided to go with emails was because we wanted to perform sentiment analysis using the 
***NLTK*** package. And we had the requirement of minimum 1k to 100k rows to fulfill. 

After doing our research, we found the Enron emails dataset with around 500k emails. That should be sufficient to clean, structure and to analyse the data for sentiment analysis.

[![View on Kaggle](https://img.shields.io/badge/Kaggle-View%20on%20Kaggle-orange)](https://www.kaggle.com/datasets/wcukierski/enron-email-dataset)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://vinothnk.github.io/Data-Wrangling-with-Programming-2/)
<center><img src="https://storage.googleapis.com/kaggle-datasets-images/55/110/b720c0cc3f965a27a2b2bfae3c815f1f/dataset-card.png"/></center>

------------------------------------------------------------------

### Data Visualisation

In my class for Data Visualisation, we were taught to use visualisation tools like Tableau and PowerBI.

For my group project, we decide to do a visualisation on the effects of Covid throughout the world.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/Data-Storytelling-with-Visualisation) 
[![View on Tableau](https://img.shields.io/badge/Tableau-View%20on%20Tableau%20Public-brightgreen)](https://public.tableau.com/views/CovidDataVisualisation_16579515462230/Storyline?:language=en-GB&publish=yes&:display_count=n&:origin=viz_share_link)


<center><img src="https://assets.entrepreneur.com/content/3x2/2000/20190909181947-sale-21635-primary-image-wide.jpeg"/></center>

------------------------------------------------------------------

### Foundation of Data Science

As this is the introduction to Data Science, I learnt the following steps in the data cycle and how to perform data analysis using Excel.

- Step 1: Business Question
- Step 2: Data Acquisition
- Step 3: Data Preparation
- Step 4: Data Modelling
- Step 5: Data Visualisation
- Step 6: Business Decision

We will be covering Steps 1 till Step 4 in this module.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/Foundation-of-Data-Science)

<center><img src="https://www.analytixlabs.co.in/blog/wp-content/uploads/2021/03/blogs-banner-7c-01-scaled-1024x724.jpg"/></center>

------------------------------------------------------------------

## Python

### Udemy - 100 Days of Coding by Angela Yu

An ongoing process in my journey to learning Python. Even though I had learnt python during my course in SUTD, working full time whilst studying part time did not allow me to fully concentrate on the lessons, with family commitments on the side as well as Covid. Hence, I decided to restart learning python to ensure I understand the basic principles of python. 

Below is the link of the repository of my 100 days of coding progress.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/vinothnk/100-Days-of-Coding)

<center><img src="images/100daysofpython.jpg"/></center>
